# hashMap

## 为什么HashMap需要加载因子

HashMap有两个问题

* 如果空间利用率高,经过哈希算法计算存储位置时,就会出现较多的哈希冲突
* 为避免hash冲突,增加数组容量,又会导致数组利用率不高

加载因子=填入表中元素个数/散列表的长度

加载因子其实就是为了在hash冲突和空间利用率找到折中点

## 解决冲突办法

### 开放地址法

Hi=(H(key)+di) MOD m,其中 i=1,2,..,k(k<=m-1)

* 线性探查法  di=1,2,3,..,m-1

就是以当前冲突位置为起点,步长为1循环查找,知道找到空的位置,如果循环找不到,表示容器已经满了

* 平方探查法 di=2,4,8,...,(m/2)^2

* 伪随机探测法:di=伪随机数序列

    缺点:

    1. 冲突较多时,查找不友好
    1. 删除节点不能真正的删除节点,只能标记为删除节点
    1. 如果哈希表空间满,还需要建立一个溢出表,来存入多出来的元素

### 再哈希法

Hi=RHi(key),其中i=1,2,..,k

当同义词出现地址冲突时,使用另一个哈希函数计算地址,直到不发生冲突

缺点:随不会出现堆积,但是会增加计算时间

### 建立公共溢出区

新增溢出表,一但hash冲突,都填入溢出表

缺点:查找冲突数据时,需要遍历溢出表才能找到数据

### 链地址法

缺点:需要额外存储空间

## 为什么加载因子是0.75

从上文我们知道，HashMap的底层其实也是哈希表（散列表），而解决冲突的方式是链地址法。HashMap的初始容量大小默认是16，为了减少冲突发生的概率，当HashMap的数组长度到达一个临界值的时候，就会触发扩容，把所有元素rehash之后再放在扩容后的容器中，这是一个相当耗时的操作。

而这个临界值就是由加载因子和当前容器的容量大小来确定的：

“临界值 = DEFAULT_INITIAL_CAPACITY * DEFAULT_LOAD_FACTOR
即默认情况下是16x0.75=12时，就会触发扩容操作。

那么为什么选择了0.75作为HashMap的加载因子呢？这个跟一个统计学里很重要的原理——泊松分布有关。

泊松分布是统计学和概率学常见的离散概率分布，适用于描述单位时间内随机事件发生的次数的概率分布。有兴趣的读者可以看看维基百科或者阮一峰老师的这篇文章：泊松分布和指数分布：10分钟教程

![泊松分布](https://picb.zhimg.com/80/v2-ac63920350b322dfba2103535661c826_720w.jpg)

等号的左边，P 表示概率，N表示某种函数关系，t 表示时间，n 表示数量。等号的右边，λ 表示事件的频率。

在HashMap的源码中有这么一段注释：

```java

* Ideally, under random hashCodes, the frequency of
* nodes in bins follows a Poisson distribution
* (http://en.wikipedia.org/wiki/Poisson_distribution) with a
* parameter of about 0.5 on average for the default resizing
* threshold of 0.75, although with a large variance because of
* resizing granularity. Ignoring variance, the expected
* occurrences of list size k are (exp(-0.5) * pow(0.5, k) /
* factorial(k)). The first values are:
* 0:    0.60653066
* 1:    0.30326533
* 2:    0.07581633
* 3:    0.01263606
* 4:    0.00157952
* 5:    0.00015795
* 6:    0.00001316
* 7:    0.00000094
* 8:    0.00000006
* more: less than 1 in ten million

```

在理想情况下，使用随机哈希码，在扩容阈值（加载因子）为0.75的情况下，节点出现在频率在Hash桶（表）中遵循参数平均为0.5的泊松分布。忽略方差，即X = λt，P(λt = k)，其中λt = 0.5的情况


计算结果如上述的列表所示，当一个bin中的链表长度达到8个元素的时候，概率为0.00000006，几乎是一个不可能事件。

所以我们可以知道，其实常数0.5是作为参数代入泊松分布来计算的，而加载因子0.75是作为一个条件，当HashMap长度为length/size ≥ 0.75时就扩容，在这个条件下，冲突后的拉链长度和概率结果为：

0:    0.60653066
1:    0.30326533
2:    0.07581633
3:    0.01263606
4:    0.00157952
5:    0.00015795
6:    0.00001316
7:    0.00000094
8:    0.00000006

那么为什么不可以是0.8或者0.6呢？

HashMap中除了哈希算法之外，有两个参数影响了性能：初始容量和加载因子。初始容量是哈希表在创建时的容量，加载因子是哈希表在其容量自动扩容之前可以达到多满的一种度量。

在维基百科来描述加载因子：

“对于开放定址法，加载因子是特别重要因素，应严格限制在0.7-0.8以下。超过0.8，查表时的CPU缓存不命中（cache missing）按照指数曲线上升。因此，一些采用开放定址法的hash库，如Java的系统库限制了加载因子为0.75，超过此值将resize散列表。
在设置初始容量时应该考虑到映射中所需的条目数及其加载因子，以便最大限度地减少扩容rehash操作次数，所以，一般在使用HashMap时建议根据预估值设置初始容量，以便减少扩容操作。

选择0.75作为默认的加载因子，完全是时间和空间成本上寻求的一种折衷选择。